{
  
    
        "post0": {
            "title": "Agreement between methods of measurement with multiple observations per individual",
            "content": "Introduction . The limits of agreement (LoA) method is widely used for assessing the agreement between two methods of measurement. The case that motivates this method is when each individual has one measurement made by each of the methods. . However, it may be also the case that we have replicate measurements by each method on each individual, so that the repeatability of the two methods can be compared. This paper shows how to apply the LoA method when we have repeated measurements on each of a group of subjects. In this case, there are two separate situations: when the true value varies and when the true value is constant. . Concepts . data = pd.read_csv(&#39;observations_310320.csv&#39;) data[&#39;errors&#39;] = data[&#39;method1&#39;] - data[&#39;method2&#39;] data[&#39;means&#39;] = (data[&#39;method1&#39;] + data[&#39;method2&#39;])/2 # data[&#39;errors&#39;] = data[&#39;errors&#39;] / data[&#39;means&#39;] data . subject method1 method2 errors means . 0 1 | 7.83 | 6.57 | 1.26 | 7.200 | . 1 1 | 7.42 | 5.62 | 1.80 | 6.520 | . 2 1 | 7.89 | 6.90 | 0.99 | 7.395 | . 3 1 | 7.12 | 6.57 | 0.55 | 6.845 | . 4 1 | 7.88 | 6.35 | 1.53 | 7.115 | . 5 2 | 6.16 | 4.06 | 2.10 | 5.110 | . 6 2 | 7.26 | 4.29 | 2.97 | 5.775 | . 7 2 | 6.71 | 4.26 | 2.45 | 5.485 | . 8 2 | 6.54 | 4.09 | 2.45 | 5.315 | . 9 2 | 4.75 | 4.71 | 0.04 | 4.730 | . 10 3 | 5.24 | 5.50 | -0.26 | 5.370 | . 11 3 | 4.86 | 5.08 | -0.22 | 4.970 | . 12 3 | 4.78 | 5.02 | -0.24 | 4.900 | . 13 3 | 6.05 | 6.01 | 0.04 | 6.030 | . 14 3 | 5.42 | 5.67 | -0.25 | 5.545 | . 15 4 | 4.21 | 4.14 | 0.07 | 4.175 | . 16 4 | 3.61 | 4.20 | -0.59 | 3.905 | . 17 4 | 3.72 | 4.61 | -0.89 | 4.165 | . 18 4 | 3.87 | 4.68 | -0.81 | 4.275 | . 19 4 | 3.92 | 5.04 | -1.12 | 4.480 | . 20 5 | 3.13 | 3.03 | 0.10 | 3.080 | . 21 5 | 2.98 | 2.86 | 0.12 | 2.920 | . 22 5 | 2.85 | 2.77 | 0.08 | 2.810 | . 23 5 | 3.17 | 2.46 | 0.71 | 2.815 | . 24 5 | 3.09 | 2.32 | 0.77 | 2.705 | . 25 6 | 3.12 | 2.43 | 0.69 | 2.775 | . 26 6 | 5.92 | 5.90 | 0.02 | 5.910 | . 27 6 | 6.42 | 5.81 | 0.61 | 6.115 | . 28 6 | 5.92 | 5.70 | 0.22 | 5.810 | . 29 7 | 6.27 | 5.76 | 0.51 | 6.015 | . 30 7 | 7.13 | 5.09 | 2.04 | 6.110 | . 31 7 | 6.62 | 4.63 | 1.99 | 5.625 | . 32 7 | 6.58 | 4.61 | 1.97 | 5.595 | . 33 8 | 6.93 | 5.09 | 1.84 | 6.010 | . 34 8 | 4.54 | 4.72 | -0.18 | 4.630 | . 35 8 | 4.81 | 4.61 | 0.20 | 4.710 | . 36 8 | 5.11 | 4.36 | 0.75 | 4.735 | . 37 8 | 5.29 | 4.20 | 1.09 | 4.745 | . 38 8 | 5.39 | 4.36 | 1.03 | 4.875 | . 39 8 | 5.57 | 4.20 | 1.37 | 4.885 | . 40 9 | 4.48 | 3.17 | 1.31 | 3.825 | . 41 9 | 4.92 | 3.12 | 1.80 | 4.020 | . 42 9 | 3.97 | 2.96 | 1.01 | 3.465 | . 43 10 | 4.22 | 4.35 | -0.13 | 4.285 | . 44 10 | 4.65 | 4.62 | 0.03 | 4.635 | . 45 10 | 4.74 | 3.16 | 1.58 | 3.950 | . 46 10 | 4.44 | 3.53 | 0.91 | 3.985 | . 47 10 | 4.50 | 3.53 | 0.97 | 4.015 | . 48 11 | 6.78 | 7.20 | -0.42 | 6.990 | . 49 11 | 6.07 | 6.09 | -0.02 | 6.080 | . 50 11 | 6.52 | 7.00 | -0.48 | 6.760 | . 51 11 | 6.42 | 7.10 | -0.68 | 6.760 | . 52 11 | 6.41 | 7.40 | -0.99 | 6.905 | . 53 11 | 5.76 | 6.80 | -1.04 | 6.280 | . 54 12 | 5.06 | 4.50 | 0.56 | 4.780 | . 55 12 | 4.72 | 4.20 | 0.52 | 4.460 | . 56 12 | 4.90 | 3.80 | 1.10 | 4.350 | . 57 12 | 4.80 | 3.80 | 1.00 | 4.300 | . 58 12 | 4.90 | 4.20 | 0.70 | 4.550 | . 59 12 | 5.10 | 4.50 | 0.60 | 4.800 | . counts = data.groupby(&#39;subject&#39;).count()[&#39;errors&#39;] counts . subject 1 5 2 5 3 5 4 5 5 5 6 4 7 4 8 7 9 3 10 5 11 6 12 6 Name: errors, dtype: int64 . Method where the true value varies . We want to estimate the mean difference and the standard deviation of differences about the mean. To do this, we must estimate two different variances: . That for repeated differences between the two methods on the same subject | That for repeated differences between the averages of the two methods across subjects | . The model is that the observed difference is the sum of the mean difference (bias), a random between subjects effect (heterogeneity) and a random error within the subject. . $$e = mu + w_{ text{inter}} + w_{ text{intra}}$$ . This method assumes that the within-subject (intra) variance is constant and observations within the subject are independent, i.e. the variance that originates the errors in our model for two given subjects is the same, but the mean is not necessarily the same. . Estimate $ sigma^2_{ text{intra}}$ . This variance can be estimated using the difference between matched pairs as a response. First, it should be checked that the variance is unrelated to the mean. Plotting the mean measurement for each subject against the standard deviation should show if there is any suggestion of that. . subject_groups = data.groupby(&#39;subject&#39;) subj_variance = subject_groups.std()[&#39;errors&#39;].sort_index() subj_mean = subject_groups.mean()[&#39;errors&#39;].sort_index() plt.scatter(subj_mean, subj_variance) plt.ylabel(&#39;Standard deviation&#39;) plt.xlabel(&#39;Mean&#39;) plt.show() . According to the article, . There is no suggestion that there is a relationship between the variability of the differences and the magnitude of the ejection fraction. . The one-way ANOVA is shown in the table below. . import statsmodels.api as sm from statsmodels.formula.api import ols data[&#39;subject&#39;] = data[&#39;subject&#39;].astype(str) lm = ols(&#39;errors ~ subject&#39;,data=data).fit() table = sm.stats.anova_lm(lm) table . df sum_sq mean_sq F PR(&gt;F) . subject 11.0 | 38.797808 | 3.527073 | 10.785875 | 1.250117e-09 | . Residual 48.0 | 15.696411 | 0.327009 | NaN | NaN | . According to the article, . The estimated variance of multiple between-method differences for the same subject is the mean square error, of the residual mean square. . var_intra = table.mean_sq[&#39;Residual&#39;] var_intra . 0.3270085565476191 . Estimate $ sigma^2_{ text{inter}}$ . The variance for differences between the average across subjects can also be found from the ANOVA table, using the difference between the mean squares for subjects and the residual mean square. . var_inter = table.mean_sq[&#39;subject&#39;] - table.mean_sq[&#39;Residual&#39;] var_inter . 3.2000648633658013 . We must divide this by a value which depends on the number of observation on each subject. If the number of observations on subject $i$ is $m_i$, this divisor is . $$ frac{ left( sum m_i right)^2 - sum m_i^2}{(n-1) sum m_i}$$ . where $n$ is the number of subjects. If all subject have the same number of observations $m$, this factor reduces to $m$. . num_samples = data.shape[0] square_of_sum = num_samples ** 2 subject_count = data.groupby(&#39;subject&#39;).count()[&#39;errors&#39;] n_subjects = subject_count.shape[0] sum_of_squares = sum(subject_count ** 2) print(f&#39;Sum of squares is {sum_of_squares}.&#39;) denominator = (square_of_sum - sum_of_squares)/((n_subjects-1) * num_samples) denominator . Sum of squares is 312. . 4.9818181818181815 . var_inter = var_inter / denominator var_inter . 0.6423487864420404 . Calculate total variance . The total variance for single differences on different subjects is then $ sigma_{ text{inter}} + sigma_{ text{intra}}$ . var = var_inter + var_intra var . 0.9693573429896596 . If the subject differences weren&#39;t accounted, the variance would be: . var_all = data[&#39;errors&#39;].std() ** 2 var_all . 0.9236308192090397 . Make Bland-Altman plot . stdev = np.sqrt(var) stdev . 0.9845594664567802 . mean = data[&#39;errors&#39;].mean() mean . 0.6021666666666667 . plt.subplots(figsize=(12, 8)) for x in set(data[&#39;subject&#39;]): d = data[data[&#39;subject&#39;] == x] plt.scatter(d[&#39;means&#39;], d[&#39;errors&#39;], marker=f&#39;${x}$&#39;, s=100) plt.axhline(mean, linestyle=&#39;--&#39;, c=&#39;black&#39;) plt.axhline(mean + 1.96 * stdev, linestyle=&#39;--&#39;, c=&#39;red&#39;) plt.axhline(mean - 1.96 * stdev, linestyle=&#39;--&#39;, c=&#39;red&#39;) plt.ylabel(&#39;Difference, RV - IC&#39;) plt.xlabel(&#39;Average of RV and IC&#39;) plt.show() .",
            "url": "https://herculanodavi.github.io/listofbizus/jupyter/2020/03/31/compound_bland_altman.html",
            "relUrl": "/jupyter/2020/03/31/compound_bland_altman.html",
            "date": " • Mar 31, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://herculanodavi.github.io/listofbizus/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://herculanodavi.github.io/listofbizus/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}